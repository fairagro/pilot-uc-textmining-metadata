{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1712d138",
   "metadata": {},
   "source": [
    "## Tutorial on How to Use the Dataset for Training\n",
    "This tutorial provides step-by-step instructions for using the dataset for training a model. The dataset is available now in the same directory.\n",
    "\"\"\"\n",
    "1. **Split the data into training and testing sets**: Split the dataset into training and testing sets using appropriate techniques such as k-fold cross-validation.\n",
    "2. **Train the model**: Train a machine learning model on the training set using an appropriate algorithm or framework.\n",
    "3. **Evaluate the model**: Evaluate the performance of the trained model on the testing set using appropriate metrics such as accuracy, precision, recall, and F1-score.\n",
    "4. **Make predictions**: Use the trained model to make predictions on new data.\n",
    "By following these steps, you can use the dataset for training a model and gain valuable insights into your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5eae84",
   "metadata": {},
   "source": [
    "### Load the datdataset\n",
    "Here you just need to load the dataset using the Huggingfac's datasets library. The dataset is available in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1985adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:51:35.635476956Z",
     "start_time": "2025-11-28T09:51:35.529605306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file_name', 'Tokens', 'ner_tags', 'Labels', 'number_of_tokens', 'Language', 'source', 'Label_counts', 'number_of_annotations', 'sentence_id'],\n",
      "        num_rows: 2722\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['file_name', 'Tokens', 'ner_tags', 'Labels', 'number_of_tokens', 'Language', 'source', 'Label_counts', 'number_of_annotations', 'sentence_id'],\n",
      "        num_rows: 319\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "full_dataset = load_from_disk(\"my_ner_dataset/sentence_split\")\n",
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2fce9",
   "metadata": {},
   "source": [
    "### Visualize the Huggingface dataset\n",
    "The datase's entries can be shown using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4a06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd04d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tokens",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ner_tags",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Labels",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "number_of_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label_counts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_of_annotations",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6f20a782-6955-4405-9afb-40b77fe09d8c",
       "rows": [
        [
         "0",
         "97dda154-93d3-4685-beff-9124e7346d68.txt",
         "['Title', ':', '\\n ', 'Abundance', 'of', 'different', 'microorganism', 'groups', 'in', 'soil', 'and', 'roots', 'in', 'a', 'field', 'trial', 'on', 'starter', 'fertilization', 'and', 'application', 'of', 'plant', 'growth', '-', 'promoting', 'microorganisms', '\\n', 'Abstract_text_1', ':', '\\n ', 'Abundance', 'of', 'different', 'microorganism', 'groups', 'in', 'soil', 'and', 'roots', 'in', 'a', 'field', 'trial', 'on', 'starter', 'fertilization', 'and', 'application', 'of', 'plant', 'growth', '-', 'promoting', 'microorganisms', '.', '\\n']",
         "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",
         "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",
         "57",
         "en",
         "BonaRes",
         "Counter()",
         "0",
         "97dda154-93d3-4685-beff-9124e7346d68-0"
        ],
        [
         "1",
         "97dda154-93d3-4685-beff-9124e7346d68.txt",
         "['Abstract_text_2', ':', '\\n ', 'Fertilizer', 'experiments', 'were', 'carried', 'out', 'as', 'plot', 'trials', 'on', 'maize', 'fields', 'over', 'the', 'years', '2021', ',', '2022', 'and', '2023', '.']",
         "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0, 7, 0, 7, 0, 9, 0]",
         "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cropSpecies', 'O', 'O', 'O', 'O', 'B-startTime', 'O', 'B-startTime', 'O', 'B-endTime', 'O']",
         "23",
         "en",
         "BonaRes",
         "Counter({'startTime': 2, 'cropSpecies': 1, 'endTime': 1})",
         "4",
         "97dda154-93d3-4685-beff-9124e7346d68-1"
        ],
        [
         "2",
         "97dda154-93d3-4685-beff-9124e7346d68.txt",
         "['The', 'fields', 'investigated', 'were', 'Wanna', 'Sand', '(', 'WS', ')', ',', 'Wanna', 'Sand', 'without', 'biogas', 'slurry', '(', 'WSo', ')', ',', 'Rostock', 'Sand', '(', 'RS', ')', 'and', 'Wanna', 'Marsch', '(', 'WM', ')', '.']",
         "[0, 0, 0, 0, 5, 6, 0, 5, 0, 0, 5, 6, 0, 0, 0, 0, 5, 0, 0, 5, 6, 0, 5, 0, 0, 5, 6, 0, 5, 0, 0]",
         "['O', 'O', 'O', 'O', 'B-soilTexture', 'I-soilTexture', 'O', 'B-soilTexture', 'O', 'O', 'B-soilTexture', 'I-soilTexture', 'O', 'O', 'O', 'O', 'B-soilTexture', 'O', 'O', 'B-soilTexture', 'I-soilTexture', 'O', 'B-soilTexture', 'O', 'O', 'B-soilTexture', 'I-soilTexture', 'O', 'B-soilTexture', 'O', 'O']",
         "31",
         "en",
         "BonaRes",
         "Counter({'soilTexture': 8})",
         "8",
         "97dda154-93d3-4685-beff-9124e7346d68-2"
        ],
        [
         "3",
         "97dda154-93d3-4685-beff-9124e7346d68.txt",
         "['On', 'the', 'WS', 'and', 'WM', 'fields', ',', '30', 'mÂ³', 'of', 'biogas', 'slurry', 'was', 'applied', 'before', 'the', 'experiment', '.']",
         "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",
         "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",
         "18",
         "en",
         "BonaRes",
         "Counter()",
         "0",
         "97dda154-93d3-4685-beff-9124e7346d68-3"
        ],
        [
         "4",
         "97dda154-93d3-4685-beff-9124e7346d68.txt",
         "['Starter', 'fertilization', 'was', 'carried', 'out', 'with', 'diammonium', 'phosphate', '(', 'DAP', ')', ',', 'microgranular', 'fertilizer', '(', 'MG', ')', 'and', 'without', '(', 'control', ')', '.']",
         "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]",
         "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']",
         "23",
         "en",
         "BonaRes",
         "Counter()",
         "0",
         "97dda154-93d3-4685-beff-9124e7346d68-4"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>Labels</th>\n",
       "      <th>number_of_tokens</th>\n",
       "      <th>Language</th>\n",
       "      <th>source</th>\n",
       "      <th>Label_counts</th>\n",
       "      <th>number_of_annotations</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68.txt</td>\n",
       "      <td>[Title, :, \\n , Abundance, of, different, micr...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>57</td>\n",
       "      <td>en</td>\n",
       "      <td>BonaRes</td>\n",
       "      <td>Counter()</td>\n",
       "      <td>0</td>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68.txt</td>\n",
       "      <td>[Abstract_text_2, :, \\n , Fertilizer, experime...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-cropSpe...</td>\n",
       "      <td>23</td>\n",
       "      <td>en</td>\n",
       "      <td>BonaRes</td>\n",
       "      <td>Counter({'startTime': 2, 'cropSpecies': 1, 'en...</td>\n",
       "      <td>4</td>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68.txt</td>\n",
       "      <td>[The, fields, investigated, were, Wanna, Sand,...</td>\n",
       "      <td>[0, 0, 0, 0, 5, 6, 0, 5, 0, 0, 5, 6, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, B-soilTexture, I-soilTexture, O, ...</td>\n",
       "      <td>31</td>\n",
       "      <td>en</td>\n",
       "      <td>BonaRes</td>\n",
       "      <td>Counter({'soilTexture': 8})</td>\n",
       "      <td>8</td>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68.txt</td>\n",
       "      <td>[On, the, WS, and, WM, fields, ,, 30, mÂ³, of, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>18</td>\n",
       "      <td>en</td>\n",
       "      <td>BonaRes</td>\n",
       "      <td>Counter()</td>\n",
       "      <td>0</td>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68.txt</td>\n",
       "      <td>[Starter, fertilization, was, carried, out, wi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>23</td>\n",
       "      <td>en</td>\n",
       "      <td>BonaRes</td>\n",
       "      <td>Counter()</td>\n",
       "      <td>0</td>\n",
       "      <td>97dda154-93d3-4685-beff-9124e7346d68-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  ...                             sentence_id\n",
       "0  97dda154-93d3-4685-beff-9124e7346d68.txt  ...  97dda154-93d3-4685-beff-9124e7346d68-0\n",
       "1  97dda154-93d3-4685-beff-9124e7346d68.txt  ...  97dda154-93d3-4685-beff-9124e7346d68-1\n",
       "2  97dda154-93d3-4685-beff-9124e7346d68.txt  ...  97dda154-93d3-4685-beff-9124e7346d68-2\n",
       "3  97dda154-93d3-4685-beff-9124e7346d68.txt  ...  97dda154-93d3-4685-beff-9124e7346d68-3\n",
       "4  97dda154-93d3-4685-beff-9124e7346d68.txt  ...  97dda154-93d3-4685-beff-9124e7346d68-4\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(full_dataset['test'][0:5])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d7d68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"O\",\"B-soilReferenceGroup\",\"I-soilReferenceGroup\", \"B-soilOrganicCarbon\", \"I-soilOrganicCarbon\", \"B-soilTexture\", \"I-soilTexture\",\n",
    "               \"B-startTime\", \"I-startTime\", \"B-endTime\", \"I-endTime\", \"B-city\", \"I-city\", \"B-duration\", \"I-duration\", \"B-cropSpecies\", \"I-cropSpecies\",\n",
    "                 \"B-soilAvailableNitrogen\", \"I-soilAvailableNitrogen\", \"B-soilDepth\", \"I-soilDepth\", \"B-region\", \"I-region\", \"B-country\", \"I-country\",\n",
    "                   \"B-longitude\", \"I-longitude\", \"B-latitude\", \"I-latitude\", \"B-cropVariety\", \"I-cropVariety\", \"B-soilPH\", \"I-soilPH\",\n",
    "                     \"B-soilBulkDensity\", \"I-soilBulkDensity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ea27b2",
   "metadata": {},
   "source": [
    "As seen in the above table the dataset contains sentences already split into to words and their respective tags. We will use this to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d939ead",
   "metadata": {},
   "source": [
    "### Align and tokenize dataset\n",
    "The dataset is split into training and test dataset. The goal is to fine-tune an encoder model using the datatset and evaluate the results using the test split. But for each modee, there exists a tokenizer that split the words according to the models preferred inputs. The follwoing function shsould do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d115541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac2295",
   "metadata": {},
   "source": [
    "Here is the application of this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7215d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'The', 'fields', 'investigated', 'were', 'Wanna', 'Sand', '(', 'W', '##S', ')', ',', 'Wanna', 'Sand', 'without', 'bio', '##gas', 's', '##lu', '##rry', '(', 'W', '##S', '##o', ')', ',', 'R', '##ost', '##ock', 'Sand', '(', 'RS', ')', 'and', 'Wanna', 'Mars', '##ch', '(', 'W', '##M', ')', '.', '[SEP]']\n",
      "[0, 0, 0, 0, 5, 6, 0, 5, 0, 0, 5, 6, 0, 0, 0, 0, 5, 0, 0, 5, 6, 0, 5, 0, 0, 5, 6, 0, 5, 0, 0]\n",
      "[-100, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 5, 6, 6, 6, 0, 5, 0, 0, 5, 6, 6, 0, 5, 6, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "inputs = tokenizer(full_dataset['test'][2][\"Tokens\"], is_split_into_words=True)\n",
    "print(inputs.tokens())\n",
    "labels = full_dataset['test'][2][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff6671",
   "metadata": {},
   "source": [
    "The following function transforms the whole dataset to a dataset that is ready to be used as an input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb80a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"Tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80850541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/2722 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2722/2722 [00:00<00:00, 11576.14 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 319/319 [00:00<00:00, 12241.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = full_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=full_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58a0a9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2722\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ea8dc",
   "metadata": {},
   "source": [
    "### Evaluation criteria\n",
    "\n",
    "The **Fâ‚ score** is a statistical measure that balances **precision** and **recall** â€” two key metrics used to evaluate the performance of models like those used in **Named Entity Recognition (NER)**.\n",
    "\n",
    "Itâ€™s particularly useful in NER because we care about **both** correctly identifying entities (**precision**) and finding **all** relevant entities (**recall**).\n",
    "\n",
    "---\n",
    "\n",
    "#### Formula\n",
    "\n",
    "$$\n",
    "F_1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}, \\qquad\n",
    "Recall = \\frac{TP}{TP + FN}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“˜ Definitions in the Context of NER\n",
    "\n",
    "| Term | Meaning in NER |\n",
    "|------|----------------|\n",
    "| **TP (True Positive)** | The model correctly identifies an entity span with the correct label (e.g., correctly detecting â€œBerlinâ€ as a `LOCATION`). |\n",
    "| **FP (False Positive)** | The model predicts an entity that does not exist in the gold annotations or assigns the wrong label (e.g., predicting â€œBerlinâ€ as `PERSON`). |\n",
    "| **FN (False Negative)** | The model fails to detect a true entity present in the gold annotations. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ddb0d",
   "metadata": {},
   "source": [
    "The following function computes the f-1 score for the model during training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65dcdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_list[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0415bd4",
   "metadata": {},
   "source": [
    "### Defining the model\n",
    "Now comes the time to load the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e41d2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define model attributes\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "# Load the pretrained BERT model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c17246c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e69d166959440d7809498f78f8971c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96cb3c0",
   "metadata": {},
   "source": [
    "### Defining the trainer \n",
    "Huggingface provides an easy to use trainer and can be loaded with the training arguments as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\", # Where to save the model\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ee244",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446cec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d942a6d",
   "metadata": {},
   "source": [
    "### Use the model \n",
    "After the model is trained and saved, you can load the best model check-point and use it to predict on new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"\" # Fill with the saved model\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
